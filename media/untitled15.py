# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LyuJXRB1gj4D2as0Lagxz28r9aGJ9fU5
"""

# Step 1: Import Required Libraries
import pandas as pd
import numpy as np
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt

# Step 2: Load the Dataset
df = pd.read_csv("/content/metro_forecast_dataset.csv", parse_dates=["DateTime"])
df.sort_values("DateTime", inplace=True)

# Step 3: Group Data by Time (Aggregate per hour)
df_grouped = df.groupby("DateTime")["TicketsBooked"].sum()

# Step 4: Train-Test Split (last 5 hours for test)
train = df_grouped[:-5]
test = df_grouped[-5:]

# Step 5: Fit the ARIMA Model
model = ARIMA(train, order=(3, 1, 2))  # You can use (p=3, d=1, q=2) or tune manually
model_fit = model.fit()

# Step 6: Forecast the next 5 time steps
forecast = model_fit.forecast(steps=5)

# Step 7: Compare Actual vs Predicted
results = pd.DataFrame({
    "Actual": test.values,
    "Predicted": forecast
}, index=test.index)

# Step 8: Evaluate the Forecast
mae = mean_absolute_error(test.values, forecast)
rmse = np.sqrt(mean_squared_error(test.values, forecast))

# Step 9: Print Results
print("📊 Forecast Results (Last 5 Samples):")
print(results)
print("\n📈 Model Evaluation Metrics:")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")

# Step 10: Plot Actual vs Predicted
plt.figure(figsize=(10, 5))
plt.plot(test.index, test.values, marker='o', label="Actual")
plt.plot(test.index, forecast, marker='x', linestyle="--", label="Predicted")
plt.title("ARIMA Forecast vs Actual (Last 5 Samples)")
plt.xlabel("DateTime")
plt.ylabel("Tickets Booked")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# 📦 Required Libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# 📁 Load the dataset
df = pd.read_csv("/content/metro_forecast_dataset.csv", parse_dates=["DateTime"])

# 🧠 Feature Engineering
df['Hour'] = df['DateTime'].dt.hour
df['DayOfWeek'] = df['DateTime'].dt.dayofweek
df['Weather'] = df['Weather'].map({'Clear': 0, 'Cloudy': 1, 'Rainy': 2})

# 🎯 Define Features and Target
features = ['Hour', 'DayOfWeek', 'IsHoliday', 'Weather']
X = df[features]
y = df['TicketsBooked']

# ✂️ Train-Test Split (last 5 for test)
X_train, X_test = X.iloc[:-5], X.iloc[-5:]
y_train, y_test = y.iloc[:-5], y.iloc[-5:]

# 🌲 Random Forest Model
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)

# 🔥 XGBoost Model
xgb = XGBRegressor(n_estimators=100, random_state=42)
xgb.fit(X_train, y_train)
xgb_pred = xgb.predict(X_test)

# 📊 Evaluation
rf_mae = mean_absolute_error(y_test, rf_pred)
rf_rmse = mean_squared_error(y_test, rf_pred)

xgb_mae = mean_absolute_error(y_test, xgb_pred)
xgb_rmse = mean_squared_error(y_test, xgb_pred)

# 📋 Display Results
results = pd.DataFrame({
    'Actual': y_test.values,
    'RandomForest_Pred': rf_pred,
    'XGBoost_Pred': xgb_pred
}, index=y_test.index)

print("📊 Prediction Results:\n", results)
print("\n📈 Metrics:")
print(f"Random Forest → MAE: {rf_mae:.2f}, RMSE: {rf_rmse:.2f}")
print(f"XGBoost       → MAE: {xgb_mae:.2f}, RMSE: {xgb_rmse:.2f}")

